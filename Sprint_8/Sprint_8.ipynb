{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuevos Planes Megaline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del sprint de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, desarrollaremos un modelo de clasificación para recomendar uno de los nuevos planes de Megaline: Smart o Ultra. Utilizaremos datos de comportamiento de los clientes que ya han cambiado a los nuevos planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción de datos**\n",
    "\n",
    "Cada observación en el dataset contiene información del comportamiento mensual sobre un usuario. La información dada es la siguiente:\n",
    "\n",
    "* __сalls__ — número de llamadas,\n",
    "* __minutes__ — duración total de la llamada en minutos,\n",
    "* __messages__ — número de mensajes de texto,\n",
    "* __mb_used__ — Tráfico de Internet utilizado en MB,\n",
    "* __is_ultra__ — plan para el mes actual (Ultra - 1, Smart - 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y Examinar el Conjunto de Datos\n",
    "Cargaremos el conjunto de datos y revisaremos sus primeros registros para entender su estructura y tipos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el conjunto de datos\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se han cargado correctamente. Cada fila representa el comportamiento de un usuario en términos de llamadas, minutos, mensajes y uso de datos (MB). La variable __is_ultra__ indica si el usuario está en el plan __Ultra (1__) o __Smart (0)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión y Corrección de Tipos de Datos\n",
    "Revisaremos los tipos de datos de cada columna y corregiremos los tipos de las columnas `calls` y `messages` a enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisar los tipos de datos de cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corregir los tipos de datos de `calls` y `messages` a enteros\n",
    "\n",
    "df['calls'] = df['calls'].astype(int)\n",
    "df['messages'] = df['messages'].astype(int)\n",
    "\n",
    "# Verificar la corrección\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tipos de datos de las columnas __calls__ y __messages__ se han corregido de __float64__ a __int32__, asegurando que los datos sean del tipo correcto para el análisis posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División del Conjunto de Datos\n",
    "Dividimos el conjunto de datos en conjuntos de entrenamiento (60%), validación (20%) y prueba (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar características y la variable objetivo\n",
    "X = df.drop(columns=['is_ultra'])\n",
    "y = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos: 60% entrenamiento, 20% prueba, 20% validación\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Mostrar los tamaños de las divisiones\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de validación: {X_val.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se han dividido en conjuntos de entrenamiento, validación y prueba, con **1928** observaciones para **entrenamiento** , **643** observaciones para **validación** y **643** para **prueba**.Esto asegura que podemos entrenar los modelos en el conjunto de entrenamiento, ajustar hiperparámetros en el conjunto de validación, y evaluar el rendimiento final en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Búsqueda de Hiperparámetros\n",
    "Realizamos una búsqueda en cuadrícula para encontrar los mejores hiperparámetros para los modelos de clasificación binaria DecisionTreeRegressor, RandomForestRegressor y LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Definir los modelos y sus hiperparámetros para la búsqueda en cuadrícula\n",
    "modelos = {\n",
    "    'Decision Tree': {\n",
    "        'modelo': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [10, 20, 30]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'modelo': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [10, 20]\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'modelo': LogisticRegression(solver='liblinear'),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Realizar búsqueda en cuadrícula para encontrar los mejores hiperparámetros para cada modelo utilizando entrenamiento y validación\n",
    "mejores_modelos = {}\n",
    "for nombre_modelo, info_modelo in modelos.items():\n",
    "    grid_search = GridSearchCV(info_modelo['modelo'], info_modelo['params'], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    mejores_modelos[nombre_modelo] = grid_search.best_estimator_\n",
    "    val_score = grid_search.score(X_val, y_val)\n",
    "    print(f\"{nombre_modelo} mejores params: {grid_search.best_params_}\")\n",
    "    print(f\"{nombre_modelo} exactitud de validación: {val_score:.4f}\")\n",
    "\n",
    "mejores_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusiones__:\n",
    "\n",
    "* __Decision Tree__: El mejor parámetro es __max_depth: 10__ con un accuracy de __0.7932__.\n",
    "* __Random Forest__: Los mejores parámetros son __n_estimators: 100__ y __max_depth: 10__ con accuracy de __0.8072__.\n",
    "* __Logistic Regression__: Los mejores parámetros son __C=1__ y __solver: liblinear__ con un accuracy de __0.7201__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de los Modelos\n",
    "Evaluamos los mejores modelos en el conjunto de prueba para medir su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejores modelos\n",
    "mejor_dt = mejores_modelos['Decision Tree']\n",
    "mejor_rf = mejores_modelos['Random Forest']\n",
    "mejor_lr = mejores_modelos['Logistic Regression']\n",
    "\n",
    "# Entrenar los modelos\n",
    "mejor_dt.fit(X_train, y_train)\n",
    "mejor_rf.fit(X_train, y_train)\n",
    "mejor_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_dt = mejor_dt.predict(X_test)\n",
    "y_pred_rf = mejor_rf.predict(X_test)\n",
    "y_pred_lr = mejor_lr.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Precisión de Decision Tree: {accuracy_dt:.4f}\")\n",
    "print(f\"Precisión de Random Forest: {accuracy_rf:.4f}\")\n",
    "print(f\"Precisión de Logistic Regression: {accuracy_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor modelo basado en la exactitud de validación\n",
    "mejor_modelo_nombre = max(mejores_modelos, key=lambda nombre: mejores_modelos[nombre].score(X_val, y_val))\n",
    "mejor_modelo = mejores_modelos[mejor_modelo_nombre]\n",
    "print(f\"Mejor modelo: {mejor_modelo_nombre}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo **Random Forest** con accuracy de **0.8040** es el más preciso en el conjunto de prueba, seguido por el **Decision Tree** y luego la **Logistic Regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el mejor modelo en el conjunto de entrenamiento completo\n",
    "mejor_modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de validación\n",
    "val_pred = mejor_modelo.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_pred)\n",
    "print(f\"Precisión del mejor modelo en el conjunto de validación: {val_accuracy:.4f}\")\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "test_pred = mejor_modelo.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "print(f\"Precisión del mejor modelo en el conjunto de prueba: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el modelo __Random Forest__ se ajusta bastante bien tanto para el conjunto de validación como para el conjunto de prueba, obteniendose un accuracy de __0.8072__ y __0.8258__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de Cordura\n",
    "Realizamos una prueba de cordura utilizando un clasificador **dummy** que **predice** la **clase más frecuente** y comparamos su rendimiento con el modelo **Random Forest**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de cordura con un clasificador dummy\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "accuracy_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(f\"Precisión del Clasificador Dummy: {accuracy_dummy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador dummy obtuvo una exactitud de **70%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Generales:\n",
    "- Se desarrolló un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud era 0.75, y el modelo `Random Forest` superó este umbral con una precisión del __`82%`__.\n",
    "\n",
    "- La segmentación de los datos en conjuntos de entrenamiento, validación y prueba se realizó adecuadamente, utilizando un 60% para entrenamiento, 20% para validación y 20% para prueba.\n",
    "\n",
    "- La búsqueda de hiperparámetros permitió optimizar los modelos, identificando los mejores parámetros para `Decision Tree`, `Random Forest`, y `Logistic Regression`.\n",
    "\n",
    "- El modelo `Random Forest` demostró ser el más efectivo en términos de precisión.\n",
    "\n",
    "- La prueba de cordura con el clasificador dummy confirmó la validez del modelo `Random Forest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1440,
    "start_time": "2024-07-03T01:47:30.842Z"
   },
   {
    "duration": 1179,
    "start_time": "2024-07-03T01:48:50.980Z"
   },
   {
    "duration": 126,
    "start_time": "2024-07-03T01:48:56.667Z"
   },
   {
    "duration": 124,
    "start_time": "2024-07-03T01:49:00.892Z"
   },
   {
    "duration": 128,
    "start_time": "2024-07-03T01:49:12.462Z"
   },
   {
    "duration": 131,
    "start_time": "2024-07-03T01:49:23.325Z"
   },
   {
    "duration": 132,
    "start_time": "2024-07-03T01:49:53.020Z"
   },
   {
    "duration": 124,
    "start_time": "2024-07-03T01:50:23.508Z"
   },
   {
    "duration": 129,
    "start_time": "2024-07-03T01:50:26.653Z"
   },
   {
    "duration": 135,
    "start_time": "2024-07-03T01:50:39.627Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
